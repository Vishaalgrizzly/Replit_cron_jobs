import requests
from bs4 import BeautifulSoup
import json
import os
import time
from openai import OpenAI

USER_PROFILE = {
    "name": "Vishaal Babu",
    "headline": "Growth Engineer | Digital Marketing Strategist | CS Engineer turned Marketer | Specialized in Building AI Agents",
    "location": "Antibes, France (Open to relocation worldwide)",
    "phone": "+33 743636710",
    "email": "vishaalgrizzly1@gmail.com",
    "portfolio": "https://linktr.ee/vishaalgrizzly",
    "linkedin": "www.linkedin.com/in/vishaalgrizzly/",
    
    "summary": (
        "Computer Science Engineer turned Digital Marketer with 5+ years of experience bridging the gap between "
        "technical product development and revenue growth. I don't just execute campaigns; I engineer them. "
        "Expert in building Data-Driven Growth Engines, automating Content Operations (N8N/LLMs), and deploying "
        "Machine Learning models (Propensity Scoring, Churn Prediction) to optimize Marketing ROAS. "
        "Proven track record in high-stakes environments (Blockchain, EdTech, SaaS) including a launch that drove 500k+ signups."
    ),
    
    "core_competencies": {
        "Strategic": [
            "Go-to-Market (GTM) Strategy", 
            "Revenue Operations (RevOps)", 
            "Product-Led Growth (PLG)", 
            "Technical SEO & AEO (Answer Engine Optimization)",
            "Conversion Rate Optimization (CRO)"
        ],
        "Technical": [
            "Marketing Automation Architecture",
            "Predictive Analytics & Modeling",
            "CRM Architecture & Lead Scoring",
            "Prompt Engineering & LLM Integration",
            "Data Visualization & Storytelling"
        ]
    },
    
    "tech_stack": {
        "Languages & Data": ["Python (Pandas, NumPy, Scikit-Learn)", "SQL", "HTML/CSS", "Streamlit"],
        "Automation & AI": ["N8N", "Zapier", "Perplexity API", "OpenAI API", "Make.com"],
        "Marketing Platforms": ["HubSpot (Admin)", "Salesforce", "Google Analytics (GA4)", "Semrush", "Ahrefs"],
        "Project Management": ["Jira", "Notion", "Trello", "Slack"],
        "Visualization": ["Power BI", "Tableau", "Matplotlib/Seaborn"]
    },

    "key_achievements": [
        "Growth at Scale: Orchestrated the full-stack digital launch for an IIT Madras Data Science program, driving 500,000+ signups.",
        "Revenue Optimization: Deployed a 'Propensity to Buy' scoring model using Python that reduced Ad Spend by 20% while maintaining conversion volume.",
        "Operational Efficiency: Built a proprietary AI Content Ops pipeline (N8N + LLMs) that reduced content drafting time by 60% and automated SEO keyword clustering.",
        "Organic Growth: Achieved 125% organic traffic growth for a SaaS client by restructuring site architecture based on 'Semantic Search' intent."
    ],

    "projects": [
        {
            "name": "Marketing Revenue Prediction Model",
            "stack": "Python, Linear Regression, Scikit-Learn",
            "description": "Built a regression model to correlate specific channel spend with Net Profit, identifying that 'Brand' campaigns had a 2x higher LTV impact than 'Promo' campaigns."
        },
        {
            "name": "AI Content Ops Ecosystem",
            "stack": "N8N, Perplexity API, Webhooks, OpenAI",
            "description": "Automated the end-to-end content workflow: from Trend Spotting (API) -> Brief Generation (LLM) -> Draft Creation -> CMS Upload."
        },
        {
            "name": "E-Commerce Customer Segmentation Engine",
            "stack": "Python, K-Means Clustering, RFM Analysis",
            "description": "Segmented a user base into 4 behavioral personas ('Whales', 'Window Shoppers', etc.) to hyper-target CRM emails, increasing open rates by 15%."
        },
        {
            "name": "Fintech Transaction Pulse",
            "stack": "Streamlit, PhonePe Pulse Data, Plotly",
            "description": "Developed an interactive geospatial dashboard visualizing millions of digital transactions to identify regional adoption trends."
        }
    ],

    "work_history": [
        {
            "role": "SEO & Web Strategy Consultant",
            "company": "SkÃ¥l International CÃ´te d'Azur",
            "dates": "Recent",
            "impact": "Leading the digital transformation of a legacy tourism association. Restructuring web architecture for modern SEO standards and implementing automated membership workflows, ensuring GDPR compilance."
        },
        {
            "role": "Content Marketer & Strategist",
            "company": "Calibraint (SaaS/Blockchain)",
            "dates": "Previous",
            "impact": "Managed B2B messaging for complex tech stacks (Blockchain, AI). Translated engineering documentation into compelling sales assets and whitepapers. Managed a content team of 5."
        },
        {
            "role": "Senior Technical Editorial In-Charge",
            "company": "Maxposure Media (Client: IIT Madras)",
            "dates": "Previous",
            "impact": "Managed the high-pressure launch of India's first online B.Sc degree. Coordinated between academic stakeholders and marketing teams to drive 500k+ applications."
        },
        {
            "role": "Technical Writer",
            "company": "Zaigo Infotech",
            "dates": "Previous",
            "impact": "Reduced churn and support tickets by authoring developer-friendly API documentation and user manuals. Bridged the communication gap between Product and Sales."
        }
    ],

    "education": [
        "M.Sc. in Digital Marketing and Artificial Intelligence | SKEMA Business School, France (Grand Ã‰cole)",
        "B.E. in Computer Science & Engineering | Anna University, India"
    ],
    
    "languages": ["English (Fluent/C2)", "French (A2 - Actively Learning)", "Hindi (Native)", "Tamil (Native)"]
}

# --- 2. CONFIGURATION ---
SEARCH_URLS = {
     "Marketing": "https://englishjobs.fr/jobs/marketing",
    "Content_Marketer": "https://englishjobs.fr/jobs/Content_Marketer",
    "Content_Marketing": "https://englishjobs.fr/jobs/content_marketing",
    "Community_Manager": "https://englishjobs.fr/jobs/community_manager", 
    "DM_Manager": "https://englishjobs.fr/jobs/digital_marketing_manager", 
    "Content_Marketing_Specialist": "https://englishjobs.fr/jobs/Content_Marketing_Specialist",  
    "Content_Marketing_Manager": "https://englishjobs.fr/jobs/Content_Marketing_Manager",  
    "Growth_Marketer": "https://englishjobs.fr/jobs/Growth_Marketer",
    "Product_Marketing_Manager": "https://englishjobs.fr/jobs/Product_Marketing_Manager",
}
STATE_FILE = "seen_jobs_ai.json"

# Secrets
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")

client = None
if OPENROUTER_API_KEY:
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY,
    )

def send_telegram(message):
    if not BOT_TOKEN or not CHAT_ID: return
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": message, "parse_mode": "Markdown"}
    try:
        requests.post(url, json=payload, timeout=10)
    except Exception as e:
        print(f"Telegram Fail: {e}")

def analyze_job_with_ai(job_title, job_link):
    print(f"ğŸ¤– AI Analyzing: {job_title}...")
    
    try:
        # Scrape Description
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(job_link, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        description_div = soup.find("div", class_="job-description") 
        if not description_div: description_div = soup.find("body")
        job_text = description_div.get_text(separator="\n", strip=True)[:4000]
        
        # PROMPT: Two Output Formats
        prompt = f"""
        ACT AS: A Career Coach for Vishaal Babu.
        CONTEXT: {json.dumps(USER_PROFILE, indent=2)}
        JOB: {job_title}
        DESC: {job_text}
        
        TASK:
        1. Analyze Match % (0-100). (Be flexible on years of experience, strict on French).
        
        2. IF MATCH > 50% (Good Job), output this format:
           ğŸ”¥ **MATCH SCORE: [Score]%**
           **Role:** {job_title}
           ğŸ’¡ **Why:** [1 sentence summary]
           âš ï¸ **Gap:** [Any missing skill/language]
           ğŸ¹ **Hook:** "[Draft 2-3 sentences connecting my N8N/Python/Growth metrics to their problem]"
           â“ **Prep:** "Ask yourself: [Hard Question]"

        3. IF MATCH < 50% (Bad Job), output this "Mini Report" format:
           â„ï¸ **LOW MATCH: [Score]%**
           **Role:** {job_title}
           ğŸ›‘ **Reason:** [1 sentence explaining why (e.g. 'Requires Native French', 'Requires Java', 'Too Senior')].
        """
        
        completion = client.chat.completions.create(
            model="xiaomi/mimo-v2-flash:free", 
            messages=[{"role": "user", "content": prompt}],
            extra_headers={"HTTP-Referer": "https://github.com/vishaalgrizzly", "X-Title": "Job Hunter Bot"},
        )
        return completion.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"AI Error: {e}")
        return None

def load_seen_jobs():
    if not os.path.exists(STATE_FILE): return set()
    try:
        with open(STATE_FILE, "r") as f: return set(json.load(f))
    except: return set()

def save_seen_jobs(jobs):
    with open(STATE_FILE, "w") as f: json.dump(list(jobs), f)

def main():
    if not client:
        print("Error: OPENROUTER_API_KEY is missing.")
        return

    print("--- AI JOB AGENT STARTED ---")
    seen_jobs = load_seen_jobs()
    start_count = len(seen_jobs)
    new_jobs_found = 0
    
    for category, url in SEARCH_URLS.items():
        try:
            print(f"Checking {category}...")
            r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
            soup = BeautifulSoup(r.text, "html.parser")
            jobs = soup.find_all("a", href=True)
            
            for job in jobs:
                if "/job/" in job["href"]:
                    link = "https://englishjobs.fr" + job["href"]
                    title = job.get_text(strip=True)
                    
                    if link in seen_jobs: continue
                    
                    # Call AI
                    ai_analysis = analyze_job_with_ai(title, link)
                    
                    # ALWAYS SEND (Transparency Mode)
                    if ai_analysis:
                        send_telegram(f"{ai_analysis}\n\nğŸ”— [View Job]({link})")
                        new_jobs_found += 1
                        
                    seen_jobs.add(link)
                    time.sleep(5) 
                    
        except Exception as e:
            print(f"Scraping Error: {e}")

    # ALWAYS SAVE MEMORY
    if len(seen_jobs) > start_count:
        save_seen_jobs(seen_jobs)
        print(f"Memory updated. Total seen: {len(seen_jobs)}")
    else:
        print("No new jobs scanned.")

    # ... inside main() function ...

    if new_jobs_found > 0:
        print(f"Sent {new_jobs_found} AI reports.")
        send_telegram(f"ğŸ **AI Batch Complete**: Analyzed {new_jobs_found} new jobs.")
    else:
        print("Run Complete. No matches found.")
        # UNCOMMENT THIS LINE TO GET THE HEARTBEAT:
        send_telegram("ğŸ¤– **AI Check Complete**: No new jobs to analyze.")

if __name__ == "__main__":
    main()

if __name__ == "__main__":
    main()
